{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214e4460",
   "metadata": {},
   "source": [
    "# Install Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a17a77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d4e47",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3e4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2d85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db13d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89beb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')).difference(set((\"never\", \"not\",\"no\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d591a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5404e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d3b24",
   "metadata": {},
   "source": [
    "# Import data and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1c6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpeCara(s:str):\n",
    "    return re.sub(r\"[^a-zA-Z]\", \"\", s) \n",
    "\n",
    "#retirer les url\n",
    "def remove_url(s:str)->str:\n",
    "    url_pattern = re.compile(r\"http?://\\S+|https?://\\S+|www\\.\\S+|//S+\")\n",
    "    return url_pattern.sub(\"r\", s)\n",
    "\n",
    "#retirer les html \n",
    "def remove_html(s:str)->str:\n",
    "    html_pattern = re.compile(r\"<.*?>\")\n",
    "    return html_pattern.sub(\"r\", s)\n",
    "\n",
    "# retirer les emojies\n",
    "def remove_emoji(s:str)->str:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\" \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        u\"\\U00002500-\\U00002BEF\"  \n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return emoji_pattern.sub(\"r\", s)\n",
    "\n",
    "def clean_and_lemmatize_string(s:str):\n",
    "    l = []\n",
    "    s_ = \" \".join([remove_html(remove_url(word)) for word in s.split()])\n",
    "    for word in word_tokenize(s_):\n",
    "        word_ = removeSpeCara((remove_emoji(word)))\n",
    "        if not word_ in stop_words and len(word_) > 1:\n",
    "                l.append(word_.lower())\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    lemma_function = WordNetLemmatizer()\n",
    "    return \" \".join([lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(l)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697ffce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(os.path.join(\"..\", \"tweets_01-08-2021.csv\"))[[\"id\", \"text\"]]\n",
    "dataframe_res = dataframe.copy()\n",
    "dataframe_res[\"text_clean\"] = dataframe_res[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec6c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 3971/56571 [00:03<00:39, 1332.29it/s]"
     ]
    }
   ],
   "source": [
    "dataframe_res[\"text_clean\"] = dataframe_res[\"text_clean\"].progress_apply(lambda s : clean_and_lemmatize_string(s))\n",
    "dataframe_res = dataframe_res[dataframe_res[\"text_clean\"].str.len() >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76862e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf363b",
   "metadata": {},
   "source": [
    "# Prediction with CNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 300\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False, sublinear_tf=True, dtype=np.float32)\n",
    "vectors = vectorizer.fit_transform(dataframe_res[\"text_clean\"] )\n",
    "terms = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(terms)\n",
    "oov_tok = ''\n",
    "embedding_dim = EMBEDDING_DIM\n",
    "max_length = MAX_SEQUENCE_LENGTH\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(dataframe_res[\"text_clean\"])\n",
    "\n",
    "text_sequences = tokenizer.texts_to_sequences(dataframe_res[\"text_clean\"])\n",
    "text_padded = pad_sequences(text_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6864765",
   "metadata": {},
   "source": [
    "- **LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = tf.keras.models.load_model(os.path.join(\"Bi-LSTM\",\"Model\", \"bidirectional_lstm_NN.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_res[\"Opinion_lstm\"] = np.asarray([(\"Positive\" if prediction>=0.5 else \"Negative\") for prediction in model_lstm.predict(text_padded)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c5b85",
   "metadata": {},
   "source": [
    "- **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e27744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = tf.keras.models.load_model(os.path.join(\"CNN\",\"Model\", \"CNN_2.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467850e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe_res[\"Opinion_cnn\"] = np.asarray([(\"Positive\" if prediction>=0.5 else \"Negative\") for prediction in model_cnn.predict(text_padded)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3abe7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_res = dataframe_res.drop(\"text_clean\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe41d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b1fd60",
   "metadata": {},
   "source": [
    "# Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab090ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe_res.to_csv(os.path.join(\"result\",\"trump_tweet_opinion_cnn_lstm.csv\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a98a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01263fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43b4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\imad eddine hajjane\\appdata\\roaming\\python\\python39\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\imad eddine hajjane\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\imad eddine hajjane\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upy-cuda111 (c:\\users\\imad eddine hajjane\\anaconda3\\envs\\tf_2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas \n",
    "!pip install nltk\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd9ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "TRAIN_DATASET = \"training_noemoticon.csv\"\n",
    "TRAIN_MODELS = ['CNN', 'Bi-LSTM', 'Transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365750ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "from nltk.data import find\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52ffb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(action ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08fb5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Imad Eddine\n",
      "[nltk_data]     Hajjane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4183fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')).difference(set((\"never\", \"not\",\"no\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a097c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpeCara(s:str):\n",
    "    return re.sub(r\"[^a-zA-Z]\", \"\", s) \n",
    "\n",
    "#retirer les url\n",
    "def remove_url(s:str)->str:\n",
    "    url_pattern = re.compile(r\"http?://\\S+|https?://\\S+|www\\.\\S+|//S+\")\n",
    "    return url_pattern.sub(\"r\", s)\n",
    "\n",
    "#retirer les html \n",
    "def remove_html(s:str)->str:\n",
    "    html_pattern = re.compile(r\"<.*?>\")\n",
    "    return html_pattern.sub(\"r\", s)\n",
    "\n",
    "# retirer les emojies\n",
    "def remove_emoji(s:str)->str:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\" \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        u\"\\U00002500-\\U00002BEF\"  \n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return emoji_pattern.sub(\"r\", s)\n",
    "\n",
    "def clean_and_lemmatize_string(s:str):\n",
    "    l = []\n",
    "    s_ = \" \".join([remove_html(remove_url(word)) for word in s.split()])\n",
    "    for word in word_tokenize(s_):\n",
    "        word_ = removeSpeCara((remove_emoji(word)))\n",
    "        if not word_ in stop_words:\n",
    "            l.append(word_.lower())\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    lemma_function = WordNetLemmatizer()\n",
    "    return \" \".join([lemma_function.lemmatize(token, tag_map[tag[0]]) for token, tag in pos_tag(l)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71739552",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b226fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(TRAIN_DATASET, encoding='latin-1')\n",
    "dataframe = dataframe.rename(columns={dataframe.columns[0]:'id', dataframe.columns[-1]: \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2612e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1599999/1599999 [17:48<00:00, 1497.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17min 40s\n",
      "Wall time: 17min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataframe[\"text\"] = dataframe[\"text\"].progress_apply(lambda s : clean_and_lemmatize_string(s))\n",
    "dataframe = dataframe[dataframe[\"text\"].str.len() >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90cc1c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe[dataframe.columns[0]].replace({4: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a2dca",
   "metadata": {},
   "source": [
    "# Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846dcdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in TRAIN_MODELS:\n",
    "    dataframe.to_csv(os.path.join(\"..\", model_path, \"train\", TRAIN_DATASET), encoding='latin-1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1748a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
